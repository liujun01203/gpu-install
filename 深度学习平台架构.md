#深度学习平台架构##1.	摘要本文将介绍Nullmax如何借助docker，kubernetes，rancher，ceph，harbor等开源组件，搭建自己的深度学习平台。Nullmax深度学习平台的目标一方面是释放硬件潜能，提高设备的利用率；另一方面是让算法、数据工程师无须关注深度学习的底层工程繁琐的细节和资源，专注于模型和算法调优，提升工作效率。本文将结合这些特点，介绍Nullmax深度学习平台的具体实现。##2.	背景介绍Nullmax内部有近百名算法工程师，他们为深度学习技术提供了最基础的保障，但是随着算力的不断进步与演进，Nullmax亟需一套简单易用的深度学习平台供算法研发人员使用。

深度学习平台，简单来说就是专注于深度学习这一垂直领域的云计算平台，典型特点就是具有GPU资源。因此，其发展可以追溯到云计算，云计算的发展经历了物理机阶段，虚拟机阶段以及当前的容器化时代。
 
![图片alt](./云计算发展趋势.png ''云计算发展趋势'')物理机模式：用户在GPU物理服务器上进行模型训练，多个用户在多台物理GPU服务器上进行模型训练，用户间GPU资源分配完全通过人工私下协调，低效且容易出错。分配到一台GPU物理服务器上的多个用户无法为GPU服务器中的训练模型定义资源边界，用户之间能够操控对方的训练任务，容易出现误操作影响对方的训练任务。 当某台GPU物理服务器资源紧张时，即使其它GPU物理服务器空闲，用户也无法使用，极大地浪费了宝贵的硬件资源。

虚拟机模式：在单个物理服务器上运行多个虚拟机（VM）。用户应用程序在虚拟机之间隔离，并提供一定程度的安全性，因为一个应用程序的信息不能被另一个应用程序自由访问。虚拟机允许更好地利用物理服务器中的资源，并允许更好的可扩展性，因此可以轻松地添加或更新应用程序，降低硬件成本等等。每个虚拟机都是一台完整的机器，在虚拟化硬件之上运行所有组件，包括其自己的操作系统。

容器模式：容器类似于虚拟机，但它们具有宽松的隔离属性，可以在应用程序之间共享操作系统（OS）。与VM类似，但容器被认为是轻量级的，容器也有自己的文件系统、CPU、内存、进程空间等。容器模式最终胜出，是因为它们有许多好处。1. 敏捷的应用程序创建和部署：与虚拟机镜像的使用相比，容器镜像的创建更加容易和高效。2.	持续开发、集成和部署：提供可靠和频繁的容器镜像构建和部署，并快速轻松地回滚。3.	跨开发、测试和生产的环境一致性：在笔记本电脑上运行与在云中运行相同。4.	资源隔离：可预测的应用程序性能。5.	资源利用：高效、高密度。
##3.	深度学习平台###3.1 深度学习平台的要求深度学习场景训练相对于一般的业务场景， 具有一些典型的特点：需要大的数据集，训练任务运行时间长但不是长期运行的任务。因此，一个针对深度学习全流程的基础架构平台，需要涵盖哪些功能呢？首先，必须实现资源隔离。在一个共享底层计算资源的集群中，用户提交的训练任务不应该受到其他任务的影响，尽可能保证GPU、CPU、内存等资源隔离。

其次，实现资源调度和共享。深度学习多使用GPU进行大量数据的训练，如果无法实现资源的动态调度和共享，这必然导致计算资源的严重浪费，如果无法实现存储资源的共享，则会造成训练无法与物理服务器隔离，存在诸多不便。因此在设计机器学习平台时，需要尽可能考虑通用的集群共享场景，例如同时支持训练数据集共享和私有，训练模型存储等功能。然后，平台需要有灵活的兼容性。目前深度学习业务发展迅速，针对不同场景的深度学习框架也越来越多，灵活的平台架构可以兼容几乎所有主流的应用框架，避免基础架构因为业务的发展而频繁变化。最后，使用和管理方便。针对深度学习的模型训练的环境搭建，数据初始化，训练过程中的日志查看等主要流程，我们要提供命令行和web界面，减少用户学习成本。针对用户可能出现的不当操作，比如数据误删、长期占有资源不使用等，需要具有一定的预防机制和策略。 ###3.2 kubernetes 以上深度学习平台的需求，可以发现kubernets是一种天然的解决方案。Kubernetes在Docker技术的基础上，可以为容器化的深度学习提供部署运行、资源调度、资源伸缩等一系列完整功能。在集群管理方面， Kubernetes具有多层次的安全防护和准入机制、支持多租户、具有强大的故障发现和自我修复能力、可扩展的资源自动调度机制以及多粒度的资源配额管理能力。同时在使用方面,Kubernetes提供了完善的管理工具，涵盖了包括开发、部署测试、运维监控在内的各个环节。   
Kubernetes属于主从分布式架构，主要由Master Node和Worker Node组成，以及包括客户端命令行工具kubectl和其它附加项。+ Master Node：作为控制节点，对集群进行调度管理； Master Node由API Server、Scheduler、Controller-Manger Server和Etcd所组成；+ Worker Node：作为真正的工作节点，运行业务应用的容器，Worker Node包含kubelet、kube proxy和Container Runtime；kubectl：用于通过命令行与API Server进行交互，而对Kubernetes进行操作，实现在集群中进行各种资源的增删改查等操作；+ Add-on：是对Kubernetes核心功能的扩展，例如增加网络和网络策略等能力。    
Kubernetes 的主要架构如下图所示：

![图片alt](./kubernetes 架构.png ''kubernetes 架构'')Kubernetes主要由以下几个核心组件组成：- etcd保存了整个集群的状态；- apiserver提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现等机制；- controller manager负责维护集群的状态，比如故障检测、自动扩展、滚动更新等；- scheduler负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上；- kubelet负责维护容器的生命周期，同时也负责Volume（CVI）和网络（CNI）的管理；- Container runtime负责镜像管理以及Pod和容器的真正运行（CRI）；- kube-proxy负责为Service提供cluster内部的服务发现和负载均衡；除了核心组件，还有一些推荐的Add-ons：-  kube-dns负责为整个集群提供DNS服务- 	Ingress Controller为服务提供外网入口- 	Heapster提供资源监控- 	Dashboard提供GUI- 	Federation提供跨可用区的集群- 	Fluentd-elasticsearch提供集群日志采集、存储与查询###3.3  分布式存储Ceph由于深度学习训练模型通常都需要大量的数据集，而为了实现训练节点的选择与数据存储位置的无关，一个分布式的存储系统就必不可少。为此，Ceph组件应运而生。Ceph是一个统一的分布式存储系统，其设计旨在性能、可靠性和可扩展性。Ceph的架构如下图所示：  ![图片alt](./Ceph架构.png ''Ceph架构'')
   Ceph的底层核心为RADOS（Reliable, Autonomic Distributed Object Store）,RADOS本身也是分布式存储系统，Ceph所有的存储功能都是基于RADOS实现。Ceph的上层应用调用本机上的librados API，再由后者通过socket与RADOS集群中的其他节点通信并完成各种操作。RADOS GateWay、RBD，CEPHFS其作用是在librados库的基础上提供抽象层次更高、更便于应用或客户端使用的上层接口。其中，RADOS GW是一个提供与Amazon S3和Swift兼容的RESTful API的gateway，以供相应的对象存储应用开发使用。RBD则提供了一个标准的块设备接口，常用于在虚拟化的场景下为虚拟机创建volume。CEPHFS则提供了POSIX接口，用户可直接通过客户端挂载使用。总的来说，Ceph能满足大部分业务的存储使用场景。从后面我们的深度学习平台的架构图也可以看到，我们的多个组件都使用到了Ceph存储。##4.	深度学习平台的架构通过对深度学习平台的需求分析，以及对一些开源组件的了解，我们搭建出了如下架构的深度学习平台，如下图所示：
 ![图片alt](./nullmax 深度学习平台架构.png ''nullmax 深度学习平台架构'')这里的存储集群即Ceph，它一方面为镜像仓库Harbor提供存储资源，另一方面为GPU集群提供Volume资源，供深度学习训练使用。镜像仓库存储用户使用到的镜像资源，并提供了用户权限管理、镜像复制等功能。用户可以借助k8s 提供的客户端工具，完成对k8s的集群管理、训练任务的发布、训练结果的查看等。##5.	深度学习平台的使用用开源软件搭建深度学习平台，很重要的一点就是需要厘清怎么去使用它。必须要在用户体验和技术难度之间取得平衡，还要对用户的行为和需求有所洞悉，并做调整，比如用户可能开始因为安全希望尽可能隔离，后面因为某些原因，又希望有一些共享。Nullmax在使用的过程中，摸索出了以下的一套使用方式。使用总体上可以分为三步： 第一步是创建一个 Docker 镜像，下面的 Dockerfile 例子是从 caffe 项目中截取出来的，此镜像提供了一个可以运行训练任务的环境，通过加入定制的启动命令和命令行参数就可以实现模型训练的功能。 

![图片alt](./dockerfile.png ''dockerfile'')第二步是实现一个标准的训练模型Job，下面是一个用yml描述的模型训练实例，通过指定容器运行的镜像即启动命令和参数，用户向集群发送一个启动训练任务的请求，服务端可以解析请求的参数和内容，并将任务提交到 Kubernetes 等后端集群中。 
![图片alt](./job.png ''job'')      
第三步是生成 得到训练模型。生成的训练模型保存在持久化存储里面。用户可以通过后端存储Ceph 提供的工具，获取训练得到的模型。##6.	总结深度学习的基础架构包含了深度学习算法、深度学习类库以及深度学习平台等多个层次的内容。根据业务的需求，我们可以选择特定的领域进行深入研究和二次开发，利用轮子和根据需求改造轮子同样重要。在深度学习与人工智能非常流行的今天，我们不仅需要重视底层基础架构，理解工程的设计与实现，还需要理解算法原理与优化，只有这样才能在合适的基础架构平台上让深度学习发挥更大的效益，真正应用到实际场景中去。